
### Health-LLM: Large Language Models are Personalized Health Learners (2024)

Large language models (LLMs) have shown great promise in capturing rich representations for diverse applications. However, their potential as personalized health learners, particularly in grounding and interpreting physiological data from wearable sensors, remains largely untapped. This paper investigates the capacity of LLMs to deliver personalized health predictions based on user context and numerical data (e.g., heart rate variability, steps, mood) that is not readily expressible as text. We present a comprehensive evaluation of eight state-of-the-art LLMs including Med-Alpaca, PMC-Llama, Asclepius, ClinicalCamel, Flan-T5, Palmyra-Med, GPT-3.5-instruct and GPT-4 on five public lifelogging datasets: PMData, LifeSnaps, GLOBEM, AW\_FB and MIT-BIH \& MIMIC-III. Our experiments cover thirteen consumer healthcare tasks encompassing stress resilience prediction to physical activity recognition and sleep disorder prediction. We also conduct an exploratory case study on LLM's personalization capability on the healthcare tasks, illustrating the promising capability of LLMs. The results reveal promising yet varying performances across different LLMs in healthcare tasks. This study provides a critical step towards understanding how to enhance LLM capabilities for personalized healthcare applications while also acknowledging important limitations before achieving real-world deployability.

<img width="1341" alt="image" src="https://github.com/ybkim95/Health-LLM/assets/45308022/b55a277c-c8a8-46bc-956a-18a566cce5d0">
